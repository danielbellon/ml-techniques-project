{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías\n",
    "\n",
    "Importamos las librerías necesarias para procesar la data con la que se va a entrenar el modelo, que en este caso son:\n",
    "+ numpy\n",
    "+ keras\n",
    "+ sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descarga del dataset\n",
    "\n",
    "Se va hacer uso del dataset _Street View House Numbers (SVHN)_ para lo cual podemos descagar tres paquetes de datos.\n",
    "\n",
    "- train\n",
    "- test\n",
    "- extra\n",
    "---\n",
    "## Local\n",
    "Puede descargar y hacer uso de la herramienta `wget` mediante el siguiente comando\n",
    "```bash\n",
    "$ pip install wget\n",
    "```\n",
    "\n",
    "---\n",
    "![Google Colab](https://colab.research.google.com/img/colab_favicon_256px.png)\n",
    "## Desde  Google Colab\n",
    "\n",
    "Si esta desde este ambiente es importante que monte su cuenta de Drive con el fin de almacenar los archivos `.npy` resultado de este notebook. Modificando `YOUR_PATH` con la carpeta en la que desea trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd '/content/drive/MyDrive/YOUR_PATH'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Si se encuentra desde la plataforma Google Colab puede ejecutar las siguientes celdas para descargar los datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://ufldl.stanford.edu/housenumbers/train.tar.gz\n",
    "!wget http://ufldl.stanford.edu/housenumbers/test.tar.gz\n",
    "!wget http://ufldl.stanford.edu/housenumbers/extra.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datasets descargados se encuentran comprimidos en formato `tar.gz` por ende procedemos a descomprimirlos con el siguiente comando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvzf train.tar.gz\n",
    "!tar -xvzf test.tar.gz\n",
    "!tar -xvzf extra.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuración\n",
    "\n",
    "Para realizar el preprocesamiento del dataset vamos a hacer uso de una serie de variables de configuración que se van a definir en siguiente celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_to_predict = 1  \t\t\t\t# Cantidad de dígitos que se quieren detectar en cada imagen (DEBE PERMANECER CONSTANTE)\n",
    "\n",
    "img_size = (180, 180)  \t\t\t\t# Tamaño al cual se va a redimensionar las imágenes (DEBE PERMANECER CONSTANTE)\n",
    "img_channels = 3  \t\t\t\t\t# Número de canales de la imagen (DEBE PERMANECER CONSTANTE)\n",
    "\n",
    "TRAIN_IMGS_PATH = 'train'  \t\t\t# Directorio donde se encuentran los datos entrenamiento (MODIFIQUE SI ES NECESARIO)\n",
    "TEST_IMGS_PATH = 'test'  \t\t\t# Directorio donde se encuentran los datos prueba (MODIFIQUE SI ES NECESARIO)\n",
    "EXTRA_TRAIN_IMGS_PATH = 'extra'  \t# Directorio donde se encuentran los datos extras (MODIFIQUE SI ES NECESARIO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de los datasets\n",
    "\n",
    "Dentro de los recursos del proyecto se podrá en encontrar la carpeta `annotations/` con los archivos `.json` con los etiquetas y características de cada imagen.\n",
    "\n",
    "Primero procedemos a cargar la información de cada archivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotations file\n",
    "with open('annotations/trainDigitStruct.json') as f:\n",
    "    dataTrain = json.load(f)\n",
    "\n",
    "with open('annotations/extraDigitStruct.json') as f:\n",
    "    extraDataTrain = json.load(f)\n",
    "\n",
    "with open('annotations/testDigitStruct.json') as f:\n",
    "    dataTest = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos los vectores que utilizaremos para almacenar la información correspondiente a las etiquetas, coordenadas de los números y la ubicación de cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = []\n",
    "labels = []\n",
    "bboxes = []\n",
    "imagePaths = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a definir una función que recibe como parámetro la información que cargamos del `.json` y la ubicación del set de imágenes a procesar, con el fin de dimensionar las coordenadas del cuadro delimitador del dígito en la imagen y agregarlo al los vectores previamente definidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_images(annotations_file, imgs_folder):\n",
    "\tfor item in annotations_file:\n",
    "\t\timagePath = os.path.sep.join([imgs_folder, item['filename']])\n",
    "\t\timage = load_img(imagePath)\n",
    "\t\t(w, h) = image.size\n",
    "\n",
    "\t\tif len(item['boxes']) != digits_to_predict:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\t# scale the bounding box coordinates relative to the dimensions of the input image\n",
    "\t\timage_boxes = []\n",
    "\t\timg_labels = []\n",
    "\t\tfor i in range(digits_to_predict):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tstartX = item['boxes'][i]['left'] / w\n",
    "\t\t\t\tstartY = item['boxes'][i]['top'] / h\n",
    "\t\t\t\tendX = (item['boxes'][i]['left'] + item['boxes'][i]['width']) / w\n",
    "\t\t\t\tendY = (item['boxes'][i]['top'] + item['boxes'][i]['height']) / h\n",
    "\t\t\t\timage_boxes.extend([startX, startY, endX, endY])\n",
    "\n",
    "\t\t\t\t# Fix to change the 10.0 label for a 0\n",
    "\t\t\t\timg_labels.append(0.0 if item['boxes'][i]['label'] == 10.0 else item['boxes'][i]['label'])\n",
    "\t\t\t# If the img does not have enough digits in it\n",
    "\t\t\texcept:\n",
    "\t\t\t\timage_boxes.extend([0, 0, 0, 0])\n",
    "\t\t\t\timg_labels.append(11)\n",
    "\n",
    "\t\t# load the image and preprocess it\n",
    "\t\tcolor_mode = 'rgb' if img_channels == 3 else 'grayscale'\n",
    "\t\timage = load_img(imagePath, target_size=(img_size), color_mode=color_mode)\n",
    "\t\t# image = tf.image.rgb_to_grayscale(image)\n",
    "\t\timage = img_to_array(image) \n",
    "\t\t\n",
    "\t\tXtrain.append(image)\n",
    "\t\tlabels.append(img_labels)\n",
    "\t\tbboxes.append(image_boxes)\n",
    "\t\timagePaths.append(imagePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos de entrenamiento\n",
    "Procedemos a ejecutar el preprocesamiento de las imágenes correspondientes al set de imágenes de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process_images(dataTrain, TRAIN_IMGS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "La siguiente celda añade el dataset extra."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pre_process_images(extraDataTrain, EXTRA_TRAIN_IMGS_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conversión a NumPy\n",
    "A continuación se procede a convertir los vectores a vectores de NumPy con el fin hacer operaciones fácilmente."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data, class labels, bounding boxes, and image paths to\n",
    "# NumPy arrays, scaling the input pixel intensities from the range\n",
    "# [0, 255] to [0, 1]\n",
    "Xtrain = np.array(Xtrain) / 255.0\n",
    "labels = np.array(labels)\n",
    "bboxes = np.array(bboxes)\n",
    "imagePaths = np.array(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14522, 180, 180, 3)\n",
      "(14522, 1)\n",
      "(14522, 4)\n",
      "(14522,)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(labels.shape)\n",
    "print(bboxes.shape)\n",
    "print(imagePaths.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Codificación\n",
    "\n",
    "Se realiza una codificación One-hot encoding a las etiquetas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14522, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Guardado\n",
    "\n",
    "Se guardan los datos en formato Numpy para utilizarlos posteriormente."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\tos.stat('preprocessed_train/')\n",
    "except:\n",
    "\tos.mkdir('preprocessed_train/')\n",
    "\n",
    "np.save(f'preprocessed_train/Xtrain.npy', Xtrain)\n",
    "np.save(f'preprocessed_train/labels.npy', labels)\n",
    "np.save(f'preprocessed_train/bboxes.npy', bboxes)\n",
    "np.save(f'preprocessed_train/imagePaths.npy', imagePaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos de prueba\n",
    "\n",
    "Inicializamos los vectores donde se van a dividir los las etiquetas, coordenadas y ubicación de la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = []\n",
    "labels = []\n",
    "bboxes = []\n",
    "imagePaths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process_images(dataTest, TEST_IMGS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conversión a NumPy\n",
    "A continuación se procede a convertir los vectores a vectores de NumPy con el fin hacer operaciones fácilmente."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xtrain = np.array(Xtrain) / 255.0\n",
    "labels = np.array(labels)\n",
    "bboxes = np.array(bboxes)\n",
    "imagePaths = np.array(imagePaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Codificación\n",
    "\n",
    "Se realiza una codificación One-hot encoding a las etiquetas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2483, 180, 180, 3)\n",
      "(2483, 10)\n",
      "(2483, 4)\n",
      "(2483,)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(labels.shape)\n",
    "print(bboxes.shape)\n",
    "print(imagePaths.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Guardado\n",
    "\n",
    "Se guardan los datos en formato Numpy para utilizarlos posteriormente."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\tos.stat('preprocessed_test/')\n",
    "except:\n",
    "\tos.mkdir('preprocessed_test/')\n",
    "\n",
    "np.save(f'preprocessed_test/Xdata.npy', Xtrain)\n",
    "np.save(f'preprocessed_test/labels.npy', labels)\n",
    "np.save(f'preprocessed_test/bboxes.npy', bboxes)\n",
    "np.save(f'preprocessed_test/imagePaths.npy', imagePaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Los archivos guardados en las carpetas preprocessed_train y preprocessed_test con extension `.npy` deben ser almacenados para el siguiente proceso. Si se encuentra en el ambiente Colab se debe ejecutar la siguiente celda para guardar los archivos en la nube dado que por el tamaño de los archivos quedan en el caché de la máquina virtual de google y **NO** persistirán en su Drive."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# [OPTIONAL] Solo en ambiente Colab\n",
    "drive.flush_and_unmount();"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "0686e6cf94abbe43e8a7895b44982613bfb801bd202c741b646291637208f550"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
