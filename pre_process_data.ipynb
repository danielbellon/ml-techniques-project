{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If running from colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://ufldl.stanford.edu/housenumbers/train.tar.gz\n",
    "!wget http://ufldl.stanford.edu/housenumbers/test.tar.gz \n",
    "!wget http://ufldl.stanford.edu/housenumbers/extra.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvzf train.tar.gz\n",
    "!tar -xvzf test.tar.gz \n",
    "!tar -xvzf extra.tar.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "digits_to_predict = 1 # Use only images with this number of digits\n",
    "\n",
    "# Input\n",
    "img_size = (180, 180)\n",
    "img_channels = 3\n",
    "\n",
    "# paths\n",
    "TRAIN_IMGS_PATH = 'train' # Directory with the training original images\n",
    "TEST_IMGS_PATH = 'test' # Directory with the test original images\n",
    "EXTRA_TRAIN_IMGS_PATH = 'extra' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotations file\n",
    "with open('annotations/trainDigitStruct.json') as f:\n",
    "    dataTrain = json.load(f)\n",
    "\n",
    "with open('annotations/extraDigitStruct.json') as f:\n",
    "    extraDataTrain = json.load(f)\n",
    "\n",
    "with open('annotations/testDigitStruct.json') as f:\n",
    "    dataTest = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = []\n",
    "labels = []\n",
    "bboxes = []\n",
    "imagePaths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_images(annotations_file, imgs_folder):\n",
    "\tfor item in annotations_file:\n",
    "\t\timagePath = os.path.sep.join([imgs_folder, item['filename']])\n",
    "\t\timage = load_img(imagePath)\n",
    "\t\t(w, h) = image.size\n",
    "\n",
    "\t\tif len(item['boxes']) != digits_to_predict:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\t# scale the bounding box coordinates relative to the dimensions of the input image\n",
    "\t\timage_boxes = []\n",
    "\t\timg_labels = []\n",
    "\t\tfor i in range(digits_to_predict):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tstartX = item['boxes'][i]['left'] / w\n",
    "\t\t\t\tstartY = item['boxes'][i]['top'] / h\n",
    "\t\t\t\tendX = (item['boxes'][i]['left'] + item['boxes'][i]['width']) / w\n",
    "\t\t\t\tendY = (item['boxes'][i]['top'] + item['boxes'][i]['height']) / h\n",
    "\t\t\t\timage_boxes.extend([startX, startY, endX, endY])\n",
    "\n",
    "\t\t\t\t# Fix to change the 10.0 label for a 0\n",
    "\t\t\t\timg_labels.append(0.0 if item['boxes'][i]['label'] == 10.0 else item['boxes'][i]['label'])\n",
    "\t\t\t# If the img does not have enough digits in it\n",
    "\t\t\texcept:\n",
    "\t\t\t\timage_boxes.extend([0, 0, 0, 0])\n",
    "\t\t\t\timg_labels.append(11)\n",
    "\n",
    "\t\t# load the image and preprocess it\n",
    "\t\tcolor_mode = 'rgb' if img_channels == 3 else 'grayscale'\n",
    "\t\timage = load_img(imagePath, target_size=(img_size), color_mode=color_mode)\n",
    "\t\t# image = tf.image.rgb_to_grayscale(image)\n",
    "\t\timage = img_to_array(image) \n",
    "\t\t\n",
    "\t\tXtrain.append(image)\n",
    "\t\tlabels.append(img_labels)\n",
    "\t\tbboxes.append(image_boxes)\n",
    "\t\timagePaths.append(imagePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process_images(dataTrain, TRAIN_IMGS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you want to iclude the extra dataset\n",
    "# pre_process_images(extraDataTrain, EXTRA_TRAIN_IMGS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data, class labels, bounding boxes, and image paths to\n",
    "# NumPy arrays, scaling the input pixel intensities from the range\n",
    "# [0, 255] to [0, 1]\n",
    "Xtrain = np.array(Xtrain) / 255.0\n",
    "labels = np.array(labels)\n",
    "bboxes = np.array(bboxes)\n",
    "imagePaths = np.array(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14522, 180, 180, 3)\n",
      "(14522, 1)\n",
      "(14522, 4)\n",
      "(14522,)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(labels.shape)\n",
    "print(bboxes.shape)\n",
    "print(imagePaths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14522, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'preprocessed_train/Xtrain.npy', Xtrain)\n",
    "np.save(f'preprocessed_train/labels.npy', labels)\n",
    "np.save(f'preprocessed_train/bboxes.npy', bboxes)\n",
    "np.save(f'preprocessed_train/imagePaths.npy', imagePaths)\n",
    "\n",
    "# If you used the extra dataset save the files with the following names\n",
    "# np.save(f'preprocessed_train/Xtrain2.npy', Xtrain)\n",
    "# np.save(f'preprocessed_train/labels2.npy', labels)\n",
    "# np.save(f'preprocessed_train/bboxes2.npy', bboxes)\n",
    "# np.save(f'preprocessed_train/imagePaths2.npy', imagePaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = []\n",
    "labels = []\n",
    "bboxes = []\n",
    "imagePaths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process_images(dataTest, TEST_IMGS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data, class labels, bounding boxes, and image paths to\n",
    "# NumPy arrays, scaling the input pixel intensities from the range\n",
    "# [0, 255] to [0, 1]\n",
    "Xtrain = np.array(Xtrain) / 255.0\n",
    "labels = np.array(labels)\n",
    "bboxes = np.array(bboxes)\n",
    "imagePaths = np.array(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2483, 180, 180, 3)\n",
      "(2483, 10)\n",
      "(2483, 4)\n",
      "(2483,)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(labels.shape)\n",
    "print(bboxes.shape)\n",
    "print(imagePaths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'preprocessed_test/Xdata.npy', Xtrain)\n",
    "np.save(f'preprocessed_test/labels.npy', labels)\n",
    "np.save(f'preprocessed_test/bboxes.npy', bboxes)\n",
    "np.save(f'preprocessed_test/imagePaths.npy', imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0686e6cf94abbe43e8a7895b44982613bfb801bd202c741b646291637208f550"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
